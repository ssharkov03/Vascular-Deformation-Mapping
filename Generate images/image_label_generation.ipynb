{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cbcfc76-36ff-4483-9d63-bbc1eac97e36",
   "metadata": {},
   "source": [
    "### Set up params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb24ae6a-f3e1-4552-bd33-3d130f922a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from ext.lab2im import utils\n",
    "from SynthSR.brain_generator import BrainGenerator\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# folder containing label maps to generate images from\n",
    "labels_folder = 'data/labels'\n",
    "# folder containing corresponding images, that will be used as target regression\n",
    "images_folder = 'data/images'\n",
    "\n",
    "# result parameters\n",
    "n_examples = 3  # number of generated examples\n",
    "result_dir = 'generated_images'  # folder where they will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7886bc0-92a4-49f4-8123-19dd45fde8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general parameters\n",
    "# We now generate 2 synthetic channels, which will both be used as input. Note that it only contains True values, since\n",
    "# we use real scans as regeression target. Bear in mind that input_channels onyl refers to synthetic channels (it never\n",
    "# includes the real regression target).\n",
    "input_channels = [True, True]\n",
    "output_channel = None  # the regression targets are not synthetic, but real\n",
    "target_res = None  # produce data at the resolution of the label maps\n",
    "output_shape = 283  # randomly crop to 128^3\n",
    "\n",
    "# label values of structure to generate from\n",
    "generation_labels = 'data/labels_classes_priors/generation_labels.npy'\n",
    "# classes associating similar structures to the same Gaussian distribution\n",
    "generation_classes = 'data/labels_classes_priors/generation_classes.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450b6a94-ca58-4596-b597-88718884b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters governing the GMM priors for the synthetic T1 and T2 scans. Note that T1s will be the the first\n",
    "# synthetic channel (as we provide t1 hyperparameters first).\n",
    "prior_means_t1_lr = np.load('data/labels_classes_priors/prior_means_t1_lr.npy')\n",
    "prior_means_t2 = np.load('data/labels_classes_priors/prior_means_t2.npy')\n",
    "prior_means = np.concatenate([prior_means_t1_lr, prior_means_t2], axis=0)\n",
    "prior_stds_t1_lr = np.load('data/labels_classes_priors/prior_stds_t1_lr.npy')\n",
    "prior_stds_t2 = np.load('data/labels_classes_priors/prior_stds_t2.npy')\n",
    "prior_stds = np.concatenate([prior_stds_t1_lr, prior_stds_t2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b57914-cae2-4541-905f-4064e761e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation parameters\n",
    "flipping = False\n",
    "scaling_bounds = 0\n",
    "rotation_bounds = 0\n",
    "shearing_bounds = 0.01\n",
    "translation_bounds = False\n",
    "nonlin_std = 10.\n",
    "bias_field_std = 0.2\n",
    "\n",
    "# blurring/downsampling parameters\n",
    "# We assume here that the T1 and T2 LR scans were not acquired at the same resolution/slice thickness. We provide the\n",
    "# corresponding resolution in the same order as for the hyperparameters. In this example we simulate:\n",
    "# 3mm coronal T1 with 3mm thickness, and 4mm sagittal T2 with 3mm thickness.\n",
    "data_res = np.array([[1., 1., 3.], [1., 4.5, 1.]])  # slice spacing\n",
    "thickness = np.array([[1., 1., 3.], [1., 3., 1.]])  # slice thickness\n",
    "downsample = False  # downsample to simulated LR\n",
    "build_reliability_maps = False  # add reliability map to input channels\n",
    "# In this example we introduce small variations in the blurring kernel, such that the downstream network is robust to\n",
    "# small changes in acquisition resolution. We provide it here with this coefficient, where the blurring simulates a\n",
    "# resolution sampled in the uniform distribution U(data_res/blur_range; data_res*blur_range). Therefore blur_range must\n",
    "# equal to 1 (no changes), or greater than 1.\n",
    "blur_range = 1.15\n",
    "# Here we have two input channels, and we want to model registration problems between the two. This may be due to head\n",
    "# movement between the two acquisitions, or the fact that the two scans were not acquired in the same coordinate space\n",
    "# (e.g. orthogonal T1, and T2 acquired along the hippocampal axis). This registration error will be simulated with\n",
    "# respect to the first input channel.\n",
    "simulate_registration_error = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37ef9e55-5708-407b-b8bb-803858e6f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_generator = BrainGenerator(labels_dir=labels_folder,\n",
    "                                 images_dir=images_folder,\n",
    "                                 generation_labels=generation_labels,\n",
    "                                 input_channels=input_channels,\n",
    "                                 output_channel=output_channel,\n",
    "                                 target_res=target_res,\n",
    "                                 output_shape=output_shape,\n",
    "                                 generation_classes=generation_classes,\n",
    "                                 prior_means=prior_means,\n",
    "                                 prior_stds=prior_stds,\n",
    "                                 prior_distributions='normal',\n",
    "                                 flipping=flipping,\n",
    "                                 scaling_bounds=scaling_bounds,\n",
    "                                 rotation_bounds=rotation_bounds,\n",
    "                                 shearing_bounds=shearing_bounds,\n",
    "                                 translation_bounds=translation_bounds,\n",
    "                                 simulate_registration_error=simulate_registration_error,\n",
    "                                 nonlin_std=nonlin_std,\n",
    "                                 bias_field_std=bias_field_std,\n",
    "                                 data_res=data_res,\n",
    "                                 thickness=thickness,\n",
    "                                 downsample=downsample,\n",
    "                                 blur_range=blur_range,\n",
    "                                 build_reliability_maps=build_reliability_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb792f-f70f-4b59-a56a-bf7fb5cad096",
   "metadata": {},
   "source": [
    "### Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c03e9ccf-7678-4d5e-9d61-fb60e86ed93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels, regression_target = brain_generator.generate_brain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15619090-5e5d-4319-bcd4-f7456076a193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 87, 283, 2), (108, 87, 283))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_channels.shape, regression_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a306497a-f2b2-45fa-9332-81616f04b74c",
   "metadata": {},
   "source": [
    "### Save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a5521-6b49-45a4-85a0-52dd4017a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(n_examples):\n",
    "\n",
    "    # generate !\n",
    "    start = time.time()\n",
    "    input_channels, regression_target = brain_generator.generate_brain()\n",
    "    end = time.time()\n",
    "    print('generation {0:d} took {1:.01f}s'.format(n + 1, end - start))\n",
    "\n",
    "    # save output image and label map\n",
    "    utils.save_volume(np.squeeze(input_channels[..., 0]), brain_generator.aff, brain_generator.header,\n",
    "                      os.path.join(result_dir, 't1_input_%s.nii.gz' % (n + 1)))\n",
    "    utils.save_volume(np.squeeze(input_channels[..., 1]), brain_generator.aff, brain_generator.header,\n",
    "                      os.path.join(result_dir, 'reliability_map_t1_input_%s.nii.gz' % (n + 1)))\n",
    "    utils.save_volume(np.squeeze(input_channels[..., 2]), brain_generator.aff, brain_generator.header,\n",
    "                      os.path.join(result_dir, 't2_input_%s.nii.gz' % (n + 1)))\n",
    "    utils.save_volume(np.squeeze(input_channels[..., 3]), brain_generator.aff, brain_generator.header,\n",
    "                      os.path.join(result_dir, 'reliability_map_t2_input_%s.nii.gz' % (n + 1)))\n",
    "    utils.save_volume(np.squeeze(regression_target), brain_generator.aff, brain_generator.header,\n",
    "                      os.path.join(result_dir, 't1_target_%s.nii.gz' % (n + 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5826c7c4-d021-42aa-9909-3379e0f12c57",
   "metadata": {},
   "source": [
    "### Get image params from original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b71c97be-5057-44a2-a13d-d18a50867624",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = sitk.ReadImage('drive/driveData/Segmentations/cropped.nii.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9925d437-9c36-4a7b-aa28-094f08bc7dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_params(image):\n",
    "    return image.GetOrigin(), image.GetDirection(), image.GetSpacing()\n",
    "\n",
    "def image_to_array(image):\n",
    "    return sitk.GetArrayFromImage(image), get_image_params(image)\n",
    "\n",
    "def array_to_image(array, params):\n",
    "    image = sitk.GetImageFromArray(array)\n",
    "    image.SetOrigin(params[0])\n",
    "    image.SetDirection(params[1])\n",
    "    image.SetSpacing(params[2])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92b41a3c-74b5-47e4-9118-74540bbf1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_image_params(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6761fa-3094-482c-a2f9-b54b759c8294",
   "metadata": {},
   "source": [
    "### View synthesis result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7c41baa8-ed74-401d-bbf9-20ac5472c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    sitk.Show(array_to_image(input_channels[..., i], params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5dd871a5-c3e4-450d-b96d-cb22a5f67307",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitk.Show(array_to_image(regression_target, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c4a09-be64-4089-afc8-a1ae72e831a8",
   "metadata": {},
   "source": [
    "### Change original images orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6f5c4aa4-a3c1-4cc2-9173-cfde6204e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "label_path = 'drive/driveData/Segmentations'\n",
    "atlas_path = 'drive/driveData/Atlases'\n",
    "\n",
    "# label_path = 'drive/Labels'\n",
    "# atlas_path = 'drive/Atlas'\n",
    "\n",
    "# seg_volume = sitk.ReadImage(label_path + '/before.nii.gz')\n",
    "# im_volume = sitk.ReadImage(atlas_path + '/before.nii.gz')\n",
    "\n",
    "seg_volume = sitk.ReadImage(label_path + '/cropped.nii.gz')\n",
    "im_volume = sitk.ReadImage(atlas_path + '/cropped.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2aa40cd7-8601-47bf-a526-c09318dbe102",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_volume_np, seg_params = image_to_array(seg_volume)\n",
    "im_volume_np, atlas_params = image_to_array(im_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c578157f-1c20-4809-926e-2eb01319079f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 87, 108)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_volume_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "98b2a66b-a4ce-452a-926d-2379adea0b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_volume_np_sw = np.swapaxes(seg_volume_np, 0, 2)\n",
    "im_volume_np_sw = np.swapaxes(im_volume_np, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b687e81a-ae9c-4b8a-86eb-ed771df640b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_volume_flipped = array_to_image(im_volume_np_sw, params)\n",
    "seg_volume_flipped = array_to_image(seg_volume_np_sw, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0969cb4d-de8e-448b-acab-bbdb46beaa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitk.Show(seg_volume_flipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecc4461-19a5-43a6-902a-f0b80e94e0c4",
   "metadata": {},
   "source": [
    "### Save image object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a03952ef-5d11-4ed7-bfd6-b28a445ff00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_writer = sitk.ImageFileWriter()\n",
    "im_writer.SetFileName(\"cropped_augmented.nii.gz\")\n",
    "im_writer.Execute(array_to_image(regression_target, params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab_env",
   "language": "python",
   "name": "colab_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
